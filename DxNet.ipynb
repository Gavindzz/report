{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "\n",
    "BATCH_NORM_MOMENTUM = 0.997\n",
    "BATCH_NORM_EPSILON = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DxNet(images, is_training, num_classes=2, depth_multiplier='1.0'):\n",
    "    possibilities = {'0.5': 48, '1.0': 116, '1.5': 176, '2.0': 224}\n",
    "    initial_depth = possibilities[depth_multiplier]\n",
    "\n",
    "    def batch_norm(x):\n",
    "        x = tf.layers.batch_normalization(\n",
    "            x, axis=3, center=True, scale=True,\n",
    "            training=is_training,\n",
    "            momentum=BATCH_NORM_MOMENTUM,\n",
    "            epsilon=BATCH_NORM_EPSILON,\n",
    "            fused=True, name='batch_norm'\n",
    "        )\n",
    "        return x\n",
    "\n",
    "    with tf.name_scope('standardize_input'):\n",
    "        x = (2.0 * images) - 1.0\n",
    "\n",
    "    with tf.variable_scope('ShuffleNetV2'):\n",
    "        params = {\n",
    "            'padding': 'SAME', 'activation_fn': tf.nn.relu,\n",
    "            'normalizer_fn': batch_norm, 'data_format': 'NHWC',\n",
    "            'weights_initializer': tf.contrib.layers.xavier_initializer()\n",
    "        }\n",
    "        with slim.arg_scope([slim.conv2d, depthwise_conv], **params):\n",
    "\n",
    "            x = slim.conv2d(x, 24, (3, 3), stride=2, scope='Conv1')\n",
    "            x = slim.max_pool2d(x, (3, 3), stride=2, padding='SAME', scope='MaxPool')\n",
    "\n",
    "            x = block(x, num_units=4, out_channels=initial_depth, scope='Stage2')\n",
    "            x = block(x, num_units=8, scope='Stage3')\n",
    "            x = block(x, num_units=4, scope='Stage4')\n",
    "\n",
    "            final_channels = 1024 if depth_multiplier != '2.0' else 2048\n",
    "            x = slim.conv2d(x, final_channels, (1, 1), stride=1, scope='Conv5')\n",
    "\n",
    "    # global average pooling\n",
    "    x = tf.reduce_mean(x, axis=[1, 2])\n",
    "\n",
    "    logits = slim.fully_connected(\n",
    "        x, num_classes, activation_fn=None, scope='classifier',\n",
    "        weights_initializer=tf.contrib.layers.xavier_initializer()\n",
    "    )\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def block(x, num_units, out_channels=None, scope='stage'):\n",
    "    with tf.variable_scope(scope):\n",
    "\n",
    "        with tf.variable_scope('unit_1'):\n",
    "            x, y = basic_unit_with_downsampling(x, out_channels)\n",
    "\n",
    "        for j in range(2, num_units + 1):\n",
    "            with tf.variable_scope('unit_%d' % j):\n",
    "                x, y = concat_shuffle_split(x, y)\n",
    "                x = basic_unit(x)\n",
    "        x = tf.concat([x, y], axis=3)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_shuffle_split(x, y):\n",
    "    with tf.name_scope('concat_shuffle_split'):\n",
    "        shape = tf.shape(x)\n",
    "        batch_size = shape[0]\n",
    "        height, width = shape[1], shape[2]\n",
    "        depth = x.shape[3].value\n",
    "\n",
    "        z = tf.stack([x, y], axis=3)  # shape [batch_size, height, width, 2, depth]\n",
    "        z = tf.transpose(z, [0, 1, 2, 4, 3])\n",
    "        z = tf.reshape(z, [batch_size, height, width, 2*depth])\n",
    "        x, y = tf.split(z, num_or_size_splits=2, axis=3)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_unit(x):\n",
    "    in_channels = x.shape[3].value\n",
    "    x = slim.conv2d(x, in_channels, (1, 1), stride=1, scope='conv1x1_before')\n",
    "    x = depthwise_conv(x, kernel=3, stride=1, activation_fn=None, scope='depthwise')\n",
    "    x = slim.conv2d(x, in_channels, (1, 1), stride=1, scope='conv1x1_after')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_unit_with_downsampling(x, out_channels=None):\n",
    "    in_channels = x.shape[3].value\n",
    "    out_channels = 2 * in_channels if out_channels is None else out_channels\n",
    "\n",
    "    y = slim.conv2d(x, in_channels, (1, 1), stride=1, scope='conv1x1_before')\n",
    "    y = depthwise_conv(y, kernel=3, stride=2, activation_fn=None, scope='depthwise')\n",
    "    y = slim.conv2d(y, out_channels // 2, (1, 1), stride=1, scope='conv1x1_after')\n",
    "\n",
    "    with tf.variable_scope('second_branch'):\n",
    "        x = depthwise_conv(x, kernel=3, stride=2, activation_fn=None, scope='depthwise')\n",
    "        x = slim.conv2d(x, out_channels // 2, (1, 1), stride=1, scope='conv1x1_after')\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@tf.contrib.framework.add_arg_scope\n",
    "def depthwise_conv(\n",
    "        x, kernel=3, stride=1, padding='SAME',\n",
    "        activation_fn=None, normalizer_fn=None,\n",
    "        weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "        data_format='NHWC', scope='depthwise_conv'):\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        assert data_format == 'NHWC'\n",
    "        in_channels = x.shape[3].value\n",
    "        W = tf.get_variable(\n",
    "            'depthwise_weights',\n",
    "            [kernel, kernel, in_channels, 1], dtype=tf.float32,\n",
    "            initializer=weights_initializer\n",
    "        )\n",
    "        x = tf.nn.depthwise_conv2d(x, W, [1, stride, stride, 1], padding, data_format='NHWC')\n",
    "        x = normalizer_fn(x) if normalizer_fn is not None else x  # batch normalization\n",
    "        x = activation_fn(x) if activation_fn is not None else x  # nonlinearity\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
